{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8927c5d4-8ef1-487f-84fd-ae31d24be3a5",
   "metadata": {},
   "source": [
    "# NeuroGenPredict: A Genetic Risk Assessment Tool for Alzheimer's Disease\n",
    "\n",
    "This tool addresses key gaps in current AD prediction methods by:\n",
    "1. Using only publicly available genetic data (no access restrictions)\n",
    "2. Requiring minimal computational resources\n",
    "3. Providing interpretable risk scores\n",
    "4. Integrating pathway-based genetic analysis with polygenic risk scores\n",
    "\n",
    "Author: [Dany Mukesha]\n",
    "\n",
    "Key Innovation: Ensemble method combining:\n",
    "- Weighted Polygenic Risk Score (wPRS) using known AD variants\n",
    "- Pathway-specific genetic burden scores\n",
    "- Population-specific risk adjustments\n",
    "- Interpretable feature importance ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f180c7-9807-464e-9dfc-8dafc9ac1466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NeuroGenPredict Validation ===\n",
      "Dataset: 1000 samples, 236 cases, 764 controls\n",
      "Warning: ABCA7 not found in genotype data\n",
      "Warning: CR1 not found in genotype data\n",
      "Warning: MS4A6A not found in genotype data\n",
      "Warning: CD33 not found in genotype data\n",
      "Warning: MS4A4E not found in genotype data\n",
      "Warning: CD2AP not found in genotype data\n",
      "Warning: EPHA1 not found in genotype data\n",
      "Warning: SORL1 not found in genotype data\n",
      "Features generated: 12 features\n",
      "Feature names: ['PRS', 'amyloid_processing_burden', 'tau_pathology_burden', 'inflammation_burden', 'lipid_metabolism_burden', 'synaptic_function_burden', 'immune_response_burden', 'PRS_adjusted', 'APOE_e4', 'TREM2', 'APOE_e2', 'APOE_TREM2_interaction']\n",
      "RF Cross-validation AUC: 0.552 ± 0.030\n",
      "GBM Cross-validation AUC: 0.542 ± 0.024\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "slice(None, 1, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 375\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# Run validation if script is executed directly\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     predictor, scores = validate_neurogenpredict()\n\u001b[32m    376\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Validation Complete ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    377\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCross-validation scores:\u001b[39m\u001b[33m\"\u001b[39m, scores)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 365\u001b[39m, in \u001b[36mvalidate_neurogenpredict\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    361\u001b[39m test_predictions = predictor.predict_risk(X.iloc[:\u001b[32m5\u001b[39m])\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# Generate sample report\u001b[39;00m\n\u001b[32m    364\u001b[39m sample_report = predictor.generate_report(\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     {k: v[:\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[33m'\u001b[39m\u001b[33m__iter__\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [v] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m test_predictions.items()},\n\u001b[32m    366\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mExample_Patient_001\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m )\n\u001b[32m    369\u001b[39m \u001b[38;5;28mprint\u001b[39m(sample_report)\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictor, cv_scores\n",
      "\u001b[31mKeyError\u001b[39m: slice(None, 1, None)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class NeuroGenPredict:\n",
    "    \"\"\"\n",
    "    Alzheimer's Disease Genetic Risk Prediction Tool\n",
    "    \n",
    "    This class implements a novel ensemble approach that combines multiple\n",
    "    genetic risk assessment methods optimized for computational efficiency\n",
    "    and interpretability.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, population: str = \"EUR\"):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with population-specific parameters\n",
    "        \n",
    "        Args:\n",
    "            population: Population ancestry code (EUR, AFR, EAS, etc.)\n",
    "        \"\"\"\n",
    "        self.population = population\n",
    "        self.models = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = []\n",
    "        self.pathway_weights = {}\n",
    "        \n",
    "        # Known AD risk variants from public GWAS (no access restrictions needed)\n",
    "        # These are well-established variants from published literature\n",
    "        self.ad_variants = {\n",
    "            'APOE_e4': {'weight': 3.68, 'chr': 19, 'pos': 45411941},  # rs429358\n",
    "            'APOE_e2': {'weight': 0.6, 'chr': 19, 'pos': 45412079},   # rs7412\n",
    "            'BIN1': {'weight': 1.15, 'chr': 2, 'pos': 127892810},     # rs744373\n",
    "            'CLU': {'weight': 1.16, 'chr': 8, 'pos': 27467686},       # rs11136000\n",
    "            'ABCA7': {'weight': 1.23, 'chr': 19, 'pos': 1063443},     # rs3764650\n",
    "            'CR1': {'weight': 1.18, 'chr': 1, 'pos': 207692049},      # rs6656401\n",
    "            'PICALM': {'weight': 1.13, 'chr': 11, 'pos': 85867875},   # rs3851179\n",
    "            'MS4A6A': {'weight': 1.12, 'chr': 11, 'pos': 60009906},   # rs610932\n",
    "            'CD33': {'weight': 1.10, 'chr': 19, 'pos': 51728477},     # rs3865444\n",
    "            'MS4A4E': {'weight': 1.09, 'chr': 11, 'pos': 59923508},   # rs670139\n",
    "            'CD2AP': {'weight': 1.10, 'chr': 6, 'pos': 47487762},     # rs9349407\n",
    "            'EPHA1': {'weight': 1.11, 'chr': 7, 'pos': 143110762},    # rs11767557\n",
    "            'TREM2': {'weight': 2.92, 'chr': 6, 'pos': 41129252},     # rs75932628\n",
    "            'SORL1': {'weight': 1.14, 'chr': 11, 'pos': 121435587}    # rs2070045\n",
    "        }\n",
    "        \n",
    "        # Biological pathway definitions for pathway-based analysis\n",
    "        self.pathways = {\n",
    "            'amyloid_processing': ['APOE', 'PSEN1', 'PSEN2', 'APP', 'BACE1', 'ADAM10'],\n",
    "            'tau_pathology': ['MAPT', 'STH', 'KANSL1'],\n",
    "            'inflammation': ['TREM2', 'CD33', 'INPP5D', 'MEF2C', 'MS4A6A'],\n",
    "            'lipid_metabolism': ['APOE', 'CLU', 'ABCA7', 'SORL1'],\n",
    "            'synaptic_function': ['PICALM', 'BIN1', 'CD2AP', 'EPHA1'],\n",
    "            'immune_response': ['CR1', 'MS4A4E', 'HLA-DRB1', 'PLCG2']\n",
    "        }\n",
    "    \n",
    "    def calculate_prs(self, genotype_data: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate Polygenic Risk Score using established AD variants\n",
    "        \n",
    "        Args:\n",
    "            genotype_data: DataFrame with variant genotypes (0, 1, 2 format)\n",
    "            \n",
    "        Returns:\n",
    "            Array of PRS values for each sample\n",
    "        \"\"\"\n",
    "        prs_scores = np.zeros(len(genotype_data))\n",
    "        \n",
    "        for variant, info in self.ad_variants.items():\n",
    "            if variant in genotype_data.columns:\n",
    "                # Apply additive genetic model with log-odds weighting\n",
    "                variant_contribution = genotype_data[variant] * np.log(info['weight'])\n",
    "                prs_scores += variant_contribution\n",
    "            else:\n",
    "                print(f\"Warning: {variant} not found in genotype data\")\n",
    "        \n",
    "        return prs_scores\n",
    "    \n",
    "    def calculate_pathway_scores(self, genotype_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate pathway-specific genetic burden scores\n",
    "        \n",
    "        This novel approach aggregates genetic variants within biological\n",
    "        pathways to provide interpretable risk components\n",
    "        \"\"\"\n",
    "        pathway_scores = pd.DataFrame()\n",
    "        \n",
    "        for pathway, genes in self.pathways.items():\n",
    "            pathway_variants = []\n",
    "            for gene in genes:\n",
    "                # Find variants associated with this gene\n",
    "                gene_variants = [col for col in genotype_data.columns \n",
    "                               if gene.upper() in col.upper()]\n",
    "                pathway_variants.extend(gene_variants)\n",
    "            \n",
    "            if pathway_variants:\n",
    "                # Calculate burden score as weighted sum of variants in pathway\n",
    "                pathway_score = genotype_data[pathway_variants].sum(axis=1)\n",
    "                pathway_scores[f'{pathway}_burden'] = pathway_score\n",
    "            else:\n",
    "                pathway_scores[f'{pathway}_burden'] = 0\n",
    "        \n",
    "        return pathway_scores\n",
    "    \n",
    "    def population_adjustment(self, scores: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply population-specific risk adjustments\n",
    "        \n",
    "        This addresses the limitation of many tools not accounting for\n",
    "        population stratification in risk assessment\n",
    "        \"\"\"\n",
    "        # Population-specific adjustment factors based on known AD prevalence\n",
    "        adjustment_factors = {\n",
    "            'EUR': 1.0,      # European (baseline)\n",
    "            'AFR': 0.8,      # African ancestry (lower APOE e4 effect)\n",
    "            'EAS': 0.9,      # East Asian\n",
    "            'AMR': 0.95,     # Admixed American\n",
    "            'SAS': 1.05      # South Asian\n",
    "        }\n",
    "        \n",
    "        factor = adjustment_factors.get(self.population, 1.0)\n",
    "        return scores * factor\n",
    "    \n",
    "    def prepare_features(self, genotype_data: pd.DataFrame, \n",
    "                        clinical_data: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Prepare comprehensive feature matrix for prediction\n",
    "        \n",
    "        Args:\n",
    "            genotype_data: Genetic variant data\n",
    "            clinical_data: Optional clinical/demographic data\n",
    "            \n",
    "        Returns:\n",
    "            Feature matrix ready for machine learning\n",
    "        \"\"\"\n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        # 1. Polygenic Risk Score\n",
    "        prs = self.calculate_prs(genotype_data)\n",
    "        features['PRS'] = prs\n",
    "        \n",
    "        # 2. Pathway-specific burden scores\n",
    "        pathway_scores = self.calculate_pathway_scores(genotype_data)\n",
    "        features = pd.concat([features, pathway_scores], axis=1)\n",
    "        \n",
    "        # 3. Population-adjusted scores\n",
    "        features['PRS_adjusted'] = self.population_adjustment(prs)\n",
    "        \n",
    "        # 4. Individual high-impact variants (for interpretability)\n",
    "        high_impact_variants = ['APOE_e4', 'TREM2', 'APOE_e2']\n",
    "        for variant in high_impact_variants:\n",
    "            if variant in genotype_data.columns:\n",
    "                features[variant] = genotype_data[variant]\n",
    "        \n",
    "        # 5. Genetic interaction terms (novel feature)\n",
    "        if all(v in genotype_data.columns for v in ['APOE_e4', 'TREM2']):\n",
    "            features['APOE_TREM2_interaction'] = (genotype_data['APOE_e4'] * \n",
    "                                                genotype_data['TREM2'])\n",
    "        \n",
    "        # 6. Clinical data integration (if available)\n",
    "        if clinical_data is not None:\n",
    "            clinical_features = ['age', 'sex', 'education_years']\n",
    "            for feature in clinical_features:\n",
    "                if feature in clinical_data.columns:\n",
    "                    features[feature] = clinical_data[feature]\n",
    "        \n",
    "        self.feature_names = features.columns.tolist()\n",
    "        return features\n",
    "    \n",
    "    def train_ensemble(self, X: pd.DataFrame, y: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Train ensemble of optimized models for AD risk prediction\n",
    "        \n",
    "        Uses computationally efficient algorithms optimized for small datasets\n",
    "        \"\"\"\n",
    "        # Scale features for better convergence\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Initialize ensemble components\n",
    "        self.models = {\n",
    "            'rf': RandomForestClassifier(\n",
    "                n_estimators=100,           # Reduced for computational efficiency\n",
    "                max_depth=10,               # Prevent overfitting\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                class_weight='balanced',    # Handle class imbalance\n",
    "                n_jobs=-1                   # Use all available cores\n",
    "            ),\n",
    "            'gbm': GradientBoostingClassifier(\n",
    "                n_estimators=100,           # Efficient ensemble size\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                min_samples_split=5,\n",
    "                subsample=0.8,              # Stochastic boosting for robustness\n",
    "                random_state=42\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Train models and evaluate performance\n",
    "        cv_scores = {}\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            model.fit(X_scaled, y)\n",
    "            scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='roc_auc')\n",
    "            cv_scores[f'{name}_auc'] = scores.mean()\n",
    "            cv_scores[f'{name}_std'] = scores.std()\n",
    "            \n",
    "            print(f\"{name.upper()} Cross-validation AUC: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "    \n",
    "    def predict_risk(self, X: pd.DataFrame) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate comprehensive risk predictions with interpretability\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing risk scores, probabilities, and feature importance\n",
    "        \"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        predictions = {}\n",
    "        \n",
    "        # Ensemble predictions\n",
    "        rf_proba = self.models['rf'].predict_proba(X_scaled)[:, 1]\n",
    "        gbm_proba = self.models['gbm'].predict_proba(X_scaled)[:, 1]\n",
    "        \n",
    "        # Weighted ensemble (RF gets higher weight due to interpretability)\n",
    "        ensemble_proba = 0.6 * rf_proba + 0.4 * gbm_proba\n",
    "        \n",
    "        predictions['risk_probability'] = ensemble_proba\n",
    "        predictions['risk_category'] = self._categorize_risk(ensemble_proba)\n",
    "        \n",
    "        # Feature importance for interpretability\n",
    "        rf_importance = self.models['rf'].feature_importances_\n",
    "        predictions['feature_importance'] = dict(zip(self.feature_names, rf_importance))\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def _categorize_risk(self, probabilities: np.ndarray) -> List[str]:\n",
    "        \"\"\"\n",
    "        Categorize continuous risk probabilities into interpretable categories\n",
    "        \"\"\"\n",
    "        categories = []\n",
    "        for prob in probabilities:\n",
    "            if prob < 0.2:\n",
    "                categories.append('Low Risk')\n",
    "            elif prob < 0.5:\n",
    "                categories.append('Moderate Risk')\n",
    "            elif prob < 0.8:\n",
    "                categories.append('High Risk')\n",
    "            else:\n",
    "                categories.append('Very High Risk')\n",
    "        return categories\n",
    "    \n",
    "    def generate_report(self, predictions: Dict[str, np.ndarray], \n",
    "                       sample_id: str = \"Sample\") -> str:\n",
    "        \"\"\"\n",
    "        Generate interpretable clinical report\n",
    "        \n",
    "        This addresses the key gap in explainability that current tools lack\n",
    "        \"\"\"\n",
    "        risk_prob = predictions['risk_probability'][0] if hasattr(predictions['risk_probability'], '__iter__') else predictions['risk_probability']\n",
    "        risk_cat = predictions['risk_category'][0] if hasattr(predictions['risk_category'], '__iter__') else predictions['risk_category']\n",
    "        \n",
    "        # Sort feature importance\n",
    "        importance = predictions['feature_importance']\n",
    "        sorted_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        \n",
    "        report = f\"\"\"\n",
    "        ===== NeuroGenPredict Risk Assessment Report =====\n",
    "        \n",
    "        Sample ID: {sample_id}\n",
    "        Risk Probability: {risk_prob:.1%}\n",
    "        Risk Category: {risk_cat}\n",
    "        Population: {self.population}\n",
    "        \n",
    "        Top Contributing Factors:\n",
    "        \"\"\"\n",
    "        \n",
    "        for feature, importance_score in sorted_features:\n",
    "            report += f\"  • {feature}: {importance_score:.3f}\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "        \n",
    "        Clinical Interpretation:\n",
    "        - This assessment is based on established genetic variants\n",
    "        - Risk is calculated using population-adjusted algorithms\n",
    "        - Results should be interpreted alongside clinical evaluation\n",
    "        - Genetic risk represents predisposition, not certainty\n",
    "        \n",
    "        Recommendations:\n",
    "        - {self._generate_recommendations(risk_prob)}\n",
    "        \"\"\"\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _generate_recommendations(self, risk_prob: float) -> str:\n",
    "        \"\"\"Generate risk-appropriate clinical recommendations\"\"\"\n",
    "        if risk_prob < 0.2:\n",
    "            return \"Continue routine health monitoring and lifestyle maintenance\"\n",
    "        elif risk_prob < 0.5:\n",
    "            return \"Consider lifestyle modifications and regular cognitive assessment\"\n",
    "        elif risk_prob < 0.8:\n",
    "            return \"Recommend genetic counseling and enhanced monitoring\"\n",
    "        else:\n",
    "            return \"Urgent genetic counseling and comprehensive neurological evaluation recommended\"\n",
    "\n",
    "# Example usage and validation function\n",
    "def validate_neurogenpredict():\n",
    "    \"\"\"\n",
    "    Demonstration function showing how to use NeuroGenPredict\n",
    "    with simulated data (representing publicly available datasets)\n",
    "    \"\"\"\n",
    "    print(\"=== NeuroGenPredict Validation ===\")\n",
    "    \n",
    "    # Simulate genotype data (in practice, this would be loaded from public datasets)\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Create realistic genotype data\n",
    "    genotype_data = pd.DataFrame({\n",
    "        'APOE_e4': np.random.choice([0, 1, 2], n_samples, p=[0.7, 0.25, 0.05]),\n",
    "        'APOE_e2': np.random.choice([0, 1, 2], n_samples, p=[0.85, 0.14, 0.01]),\n",
    "        'TREM2': np.random.choice([0, 1], n_samples, p=[0.99, 0.01]),\n",
    "        'BIN1': np.random.choice([0, 1, 2], n_samples, p=[0.3, 0.5, 0.2]),\n",
    "        'CLU': np.random.choice([0, 1, 2], n_samples, p=[0.4, 0.45, 0.15]),\n",
    "        'PICALM': np.random.choice([0, 1, 2], n_samples, p=[0.35, 0.5, 0.15])\n",
    "    })\n",
    "    \n",
    "    # Simulate clinical outcomes (AD cases vs controls)\n",
    "    # Higher genetic risk leads to higher probability of AD\n",
    "    risk_factors = (genotype_data['APOE_e4'] * 0.5 + \n",
    "                   genotype_data['TREM2'] * 1.0 + \n",
    "                   genotype_data['BIN1'] * 0.1)\n",
    "    \n",
    "    y = np.random.binomial(1, 1 / (1 + np.exp(-risk_factors + 1.5)))\n",
    "    \n",
    "    print(f\"Dataset: {n_samples} samples, {sum(y)} cases, {n_samples-sum(y)} controls\")\n",
    "    \n",
    "    # Initialize and train the predictor\n",
    "    predictor = NeuroGenPredict(population=\"EUR\")\n",
    "    X = predictor.prepare_features(genotype_data)\n",
    "    \n",
    "    print(f\"Features generated: {X.shape[1]} features\")\n",
    "    print(\"Feature names:\", X.columns.tolist())\n",
    "    \n",
    "    # Train models\n",
    "    cv_scores = predictor.train_ensemble(X, y)\n",
    "    \n",
    "    # Make predictions on a subset\n",
    "    test_predictions = predictor.predict_risk(X.iloc[:5])\n",
    "    \n",
    "    # Generate sample report\n",
    "    sample_report = predictor.generate_report(\n",
    "        {k: v[:1] if hasattr(v, '__iter__') else [v] for k, v in test_predictions.items()},\n",
    "        \"Example_Patient_001\"\n",
    "    )\n",
    "    \n",
    "    print(sample_report)\n",
    "    \n",
    "    return predictor, cv_scores\n",
    "\n",
    "# Run validation if script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    predictor, scores = validate_neurogenpredict()\n",
    "    print(\"\\n=== Validation Complete ===\")\n",
    "    print(\"Cross-validation scores:\", scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
